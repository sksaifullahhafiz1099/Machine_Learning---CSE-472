{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
    "        self.bias = np.zeros((1, output_dim))\n",
    "        self.input = None  # To store the input for backward pass\n",
    "        self.d_weights = None  # To store gradients for weights\n",
    "        self.d_bias = None    # To store gradients for bias\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Save the input for the backward pass\n",
    "        self.input = X\n",
    "        # Compute the output\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, d_out, learning_rate):\n",
    "        # Gradient of the loss with respect to the weights and bias\n",
    "        self.d_weights = np.dot(self.input.T, d_out)\n",
    "        self.d_bias = np.sum(d_out, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient of the loss with respect to the input\n",
    "        d_input = np.dot(d_out, self.weights.T)\n",
    "\n",
    "        return d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, X):\n",
    "        # ReLU forward pass\n",
    "        self.input = X\n",
    "        return np.maximum(0, X)\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        # Gradient for ReLU\n",
    "        return d_out * (self.input > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    def __init__(self, dim, epsilon=1e-5, momentum=0.9):\n",
    "        self.gamma = np.ones(dim)\n",
    "        self.beta = np.zeros(dim)\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = np.zeros(dim)\n",
    "        self.running_var = np.zeros(dim)\n",
    "        self.input = None  # To store the input for the backward pass\n",
    "\n",
    "    def forward(self, X, training=True):\n",
    "        if training:\n",
    "            # Calculate batch statistics\n",
    "            self.mean = np.mean(X, axis=0)\n",
    "            self.var = np.var(X, axis=0)\n",
    "            self.input = X\n",
    "\n",
    "            # Normalize the input\n",
    "            self.X_norm = (X - self.mean) / np.sqrt(self.var + self.epsilon)\n",
    "            out = self.gamma * self.X_norm + self.beta\n",
    "\n",
    "            # Update running statistics\n",
    "            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * self.mean\n",
    "            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * self.var\n",
    "        else:\n",
    "            # Use running statistics for inference\n",
    "            X_norm = (X - self.running_mean) / np.sqrt(self.running_var + self.epsilon)\n",
    "            out = self.gamma * X_norm + self.beta\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out, learning_rate):\n",
    "        # Gradient computation for batch normalization\n",
    "        N, D = d_out.shape\n",
    "\n",
    "        # Intermediate values from forward pass\n",
    "        X_mu = self.input - self.mean\n",
    "        std_inv = 1. / np.sqrt(self.var + self.epsilon)\n",
    "\n",
    "        dX_norm = d_out * self.gamma\n",
    "        dvar = np.sum(dX_norm * X_mu, axis=0) * -0.5 * std_inv**3\n",
    "        dmean = np.sum(dX_norm * -std_inv, axis=0) + dvar * np.mean(-2. * X_mu, axis=0)\n",
    "\n",
    "        # Gradient w.r.t. input\n",
    "        dX = (dX_norm * std_inv) + (dvar * 2 * X_mu / N) + (dmean / N)\n",
    "        self.gamma -= learning_rate * np.sum(d_out * self.X_norm, axis=0)\n",
    "        self.beta -= learning_rate * np.sum(d_out, axis=0)\n",
    "        \n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_rate):\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, X, training=True):\n",
    "        if training:\n",
    "            # Create dropout mask\n",
    "            self.mask = np.random.rand(*X.shape) > self.dropout_rate\n",
    "            return X * self.mask / (1 - self.dropout_rate)\n",
    "        else:\n",
    "            # During inference, do nothing\n",
    "            return X\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        # Apply dropout mask to gradient\n",
    "        return d_out * self.mask / (1 - self.dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = {}  # First moment vector\n",
    "        self.v = {}  # Second moment vector\n",
    "        self.t = 0   # Time step\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        self.t += 1\n",
    "        updated_params = {}\n",
    "\n",
    "        for key in params:\n",
    "            # Initialize moments if not already done\n",
    "            if key not in self.m:\n",
    "                self.m[key] = [np.zeros_like(grads[key][0]),np.zeros_like(grads[key][1])]\n",
    "                self.v[key] = [np.zeros_like(grads[key][0]),np.zeros_like(grads[key][1])]\n",
    "\n",
    "            # Update biased first moment estimate\n",
    "            self.m[key][0] = self.beta1 * self.m[key][0] + (1 - self.beta1) * grads[key][0]\n",
    "            self.m[key][1] = self.beta1 * self.m[key][1] + (1 - self.beta1) * grads[key][1]\n",
    "\n",
    "            # Update biased second raw moment estimate\n",
    "            self.v[key][0] = self.beta2 * self.v[key][0] + (1 - self.beta2) * (grads[key][0] ** 2)\n",
    "            self.v[key][1] = self.beta2 * self.v[key][1] + (1 - self.beta2) * (grads[key][1] ** 2)\n",
    "\n",
    "            # Compute bias-corrected first and second moment estimates\n",
    "            m_hat_weights = self.m[key][0] / (1 - self.beta1 ** self.t)\n",
    "            m_hat_bias = self.m[key][1] / (1 - self.beta1 ** self.t)\n",
    "            v_hat_weights = self.v[key][0] / (1 - self.beta2 ** self.t)\n",
    "            v_hat_bias = self.v[key][1] / (1 - self.beta2 ** self.t)\n",
    "\n",
    "            # Update parameters\n",
    "            updated_params[key] =[params[key][0] - self.learning_rate * m_hat_weights / (np.sqrt(v_hat_weights) + self.epsilon),\n",
    "                                    params[key][1] - self.learning_rate * m_hat_bias / (np.sqrt(v_hat_bias) + self.epsilon)]\n",
    "\n",
    "        return updated_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, X):\n",
    "        exps = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "        self.output = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        return self.output * (d_out - np.sum(d_out * self.output, axis=1, keepdims=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate):\n",
    "        # Create a list of layers\n",
    "        self.layers = []\n",
    "        \n",
    "        # Add first Dense layer\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            self.layers.append(DenseLayer(prev_dim, hidden_dim))\n",
    "            self.layers.append(BatchNormalization(hidden_dim))\n",
    "            self.layers.append(ReLU())\n",
    "            self.layers.append(Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Add final Dense layer\n",
    "        self.layers.append(DenseLayer(prev_dim, output_dim))\n",
    "        self.layers.append(Softmax())\n",
    "\n",
    "    def forward(self, X, training=True):\n",
    "        # Forward pass through all layers\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                X = layer.forward(X, training)\n",
    "            elif isinstance(layer, BatchNormalization):\n",
    "                X = layer.forward(X, training)\n",
    "            else:\n",
    "                X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    def backward(self, d_out, learning_rate):\n",
    "        # Backward pass through all layers in reverse order\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, (DenseLayer, BatchNormalization)):\n",
    "                d_out = layer.backward(d_out, learning_rate)\n",
    "            elif isinstance(layer, (ReLU, Dropout, Softmax)):\n",
    "                d_out = layer.backward(d_out)\n",
    "\n",
    "    def update_params(self, adam_optimizer):\n",
    "        # Prepare parameter and gradient dictionaries\n",
    "        params = {}\n",
    "        grads = {}\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, DenseLayer):\n",
    "                # Store weights and biases in params dictionary\n",
    "                params[id(layer)] = [layer.weights,layer.bias]\n",
    "                \n",
    "                # Store gradients for weights and biases in grads dictionary\n",
    "                grads[id(layer)] = [layer.d_weights,layer.d_bias]\n",
    "        \n",
    "        # Update parameters using Adam optimizer\n",
    "        updated_params = adam_optimizer.update(params, grads)\n",
    "\n",
    "        # Update the layers with the new parameters\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, DenseLayer):\n",
    "                layer.weights = updated_params[id(layer)][0]\n",
    "                layer.bias = updated_params[id(layer)][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Load the test dataset separately\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/938 [00:00<00:31, 29.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 57.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  47815\n",
      "Epoch [1/40], Loss: 626.5752, Accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 39.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  51083\n",
      "Epoch [2/40], Loss: 419.0253, Accuracy: 0.8514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 65.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  51779\n",
      "Epoch [3/40], Loss: 385.3202, Accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 65.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  52125\n",
      "Epoch [4/40], Loss: 366.2263, Accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:18<00:00, 51.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  52426\n",
      "Epoch [5/40], Loss: 353.7467, Accuracy: 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  52765\n",
      "Epoch [6/40], Loss: 339.6976, Accuracy: 0.8794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 62.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  52962\n",
      "Epoch [7/40], Loss: 332.4082, Accuracy: 0.8827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53087\n",
      "Epoch [8/40], Loss: 324.8517, Accuracy: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:18<00:00, 50.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53227\n",
      "Epoch [9/40], Loss: 319.2861, Accuracy: 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:18<00:00, 51.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53453\n",
      "Epoch [10/40], Loss: 311.0922, Accuracy: 0.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:19<00:00, 48.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53549\n",
      "Epoch [11/40], Loss: 306.7547, Accuracy: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:13<00:00, 67.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53646\n",
      "Epoch [12/40], Loss: 302.9173, Accuracy: 0.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53813\n",
      "Epoch [13/40], Loss: 296.8247, Accuracy: 0.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:20<00:00, 44.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  53914\n",
      "Epoch [14/40], Loss: 292.9289, Accuracy: 0.8986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:17<00:00, 52.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54012\n",
      "Epoch [15/40], Loss: 290.8124, Accuracy: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54128\n",
      "Epoch [16/40], Loss: 284.0946, Accuracy: 0.9021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:18<00:00, 50.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54099\n",
      "Epoch [17/40], Loss: 286.5020, Accuracy: 0.9016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 63.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54262\n",
      "Epoch [18/40], Loss: 280.4582, Accuracy: 0.9044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54335\n",
      "Epoch [19/40], Loss: 277.9931, Accuracy: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 63.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54403\n",
      "Epoch [20/40], Loss: 275.4207, Accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 64.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54398\n",
      "Epoch [21/40], Loss: 274.4675, Accuracy: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 63.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54425\n",
      "Epoch [22/40], Loss: 272.7300, Accuracy: 0.9071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 63.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54593\n",
      "Epoch [23/40], Loss: 269.5281, Accuracy: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 62.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54635\n",
      "Epoch [24/40], Loss: 266.3342, Accuracy: 0.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 64.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54654\n",
      "Epoch [25/40], Loss: 265.7343, Accuracy: 0.9109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 58.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54759\n",
      "Epoch [26/40], Loss: 263.1360, Accuracy: 0.9126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 64.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54769\n",
      "Epoch [27/40], Loss: 261.6918, Accuracy: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:17<00:00, 53.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54784\n",
      "Epoch [28/40], Loss: 261.4109, Accuracy: 0.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54927\n",
      "Epoch [29/40], Loss: 253.9948, Accuracy: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54920\n",
      "Epoch [30/40], Loss: 257.2245, Accuracy: 0.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55050\n",
      "Epoch [31/40], Loss: 250.6792, Accuracy: 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  54962\n",
      "Epoch [32/40], Loss: 253.2972, Accuracy: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55135\n",
      "Epoch [33/40], Loss: 250.6781, Accuracy: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55112\n",
      "Epoch [34/40], Loss: 247.5781, Accuracy: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55182\n",
      "Epoch [35/40], Loss: 246.3319, Accuracy: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55260\n",
      "Epoch [36/40], Loss: 247.2262, Accuracy: 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55240\n",
      "Epoch [37/40], Loss: 242.8576, Accuracy: 0.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 62.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55337\n",
      "Epoch [38/40], Loss: 243.0136, Accuracy: 0.9223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 66.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55320\n",
      "Epoch [39/40], Loss: 241.5300, Accuracy: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 64.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  60000 correct:  55404\n",
      "Epoch [40/40], Loss: 241.6243, Accuracy: 0.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 28 * 28  # Image size (28x28)\n",
    "hidden_dims = [128, 64]  # Hidden layers\n",
    "output_dim = 10  # Number of classes (0-9)\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 40\n",
    "\n",
    "# Initialize the model\n",
    "model = FeedForwardNeuralNetwork(input_dim, hidden_dims, output_dim, dropout_rate)\n",
    "adam_optimizer = AdamOptimizer(learning_rate)\n",
    "\n",
    "# DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm.tqdm(train_loader):\n",
    "        # Flatten images\n",
    "        images = images.view(-1, 28 * 28).numpy()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.forward(images, training=True)\n",
    "        \n",
    "        # One-hot encoding for labels\n",
    "        one_hot_labels = np.eye(output_dim)[labels.numpy()]\n",
    "\n",
    "        # Compute loss (cross-entropy loss)\n",
    "        loss = -np.sum(one_hot_labels * np.log(outputs + 1e-8)) / len(labels)\n",
    "        epoch_loss += loss\n",
    "\n",
    "        # Backward pass\n",
    "        d_out = outputs - np.eye(output_dim)[labels.numpy()]\n",
    "        model.backward(d_out, learning_rate)\n",
    "\n",
    "        # Update parameters\n",
    "        model.update_params(adam_optimizer)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predictions = np.argmax(outputs, axis=1)\n",
    "        correct += (predictions == labels.numpy()).sum()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Display epoch results\n",
    "    print(\"total: \",total,\"correct: \",correct)\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# DataLoader for testing\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Testing phase\n",
    "model_accuracy = 0\n",
    "model_total = 0\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    # Flatten images\n",
    "    images = images.view(-1, 28 * 28).numpy()\n",
    "\n",
    "    # Forward pass (inference mode)\n",
    "    outputs = model.forward(images, training=False)\n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "\n",
    "    # Collect results\n",
    "    all_predictions.extend(predictions)\n",
    "    all_true_labels.extend(labels.numpy())\n",
    "\n",
    "# Calculate accuracy using sklearn\n",
    "accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('fashion_mnist_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "with open('fashion_mnist_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.32%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run the model on the test data\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "import torch\n",
    "\n",
    "# Disable gradient computation for testing\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Flatten the images\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "\n",
    "        # Forward pass through the loaded model\n",
    "        outputs = loaded_model.forward(images)\n",
    "\n",
    "        # Get the predicted class (highest probability)\n",
    "        predictions = np.argmax(outputs, axis=1)\n",
    "\n",
    "        # Collect predictions and true labels for accuracy computation\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
